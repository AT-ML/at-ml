{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf71f01",
   "metadata": {},
   "source": [
    "## In this notebook, we will demostrate how to run some local machine learning experiments and collect the performance measurements. These measurements will be later used to train the IRT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fiscal-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import atml.measure\n",
    "import atml.exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-prince",
   "metadata": {},
   "source": [
    "## To set up the machine learning experiments, we need to first define the datasets and models. This toolbox requires the datasets and models to be indexed by python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "better-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {0: 'iris',\n",
    "             1: 'digits',\n",
    "             2: 'wine'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outer-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {0: 'lr',\n",
    "              1: 'rf',\n",
    "              2: 'nb'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c669f",
   "metadata": {},
   "source": [
    "## Furthermore, we also need to provide two functions to load the datasets and declare the models. We assume the datasets to be represented as numpy.ndarray, with x as features, y as target. The model should have the same format as sklearn.predictor, with fit() as the training function, and predict_proba() as the function to predict probability vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "geographic-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ref):\n",
    "    if ref == 'iris':\n",
    "        x, y = sklearn.datasets.load_iris(return_X_y=True)\n",
    "    elif ref == 'digits':\n",
    "        x, y = sklearn.datasets.load_digits(return_X_y=True)\n",
    "    elif ref == 'wine':\n",
    "        x, y = sklearn.datasets.load_wine(return_X_y=True)\n",
    "    return x, y\n",
    "\n",
    "def get_model(ref):\n",
    "    if ref == 'lr':\n",
    "        mdl = LogisticRegression()\n",
    "    elif ref == 'rf':\n",
    "        mdl = RandomForestClassifier()\n",
    "    elif ref == 'nb':\n",
    "        mdl = GaussianNB()\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe98ca61",
   "metadata": {},
   "source": [
    "## For this example, we use the built-in measure of Brier score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b622e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = atml.measure.BS()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f90d80",
   "metadata": {},
   "source": [
    "## Now we can use the built-in function to perform an exhaustive testing, that is, to test all combinations of different datasets and models, and collect the corresponding performance measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "finished-living",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sh/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/sh/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "res = atml.exp.get_exhaustive_testing(data_dict, get_data, model_dict, get_model, measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1853de01",
   "metadata": {},
   "source": [
    "## We can check the results with Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aging-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_idx</th>\n",
       "      <th>data_ref</th>\n",
       "      <th>model_idx</th>\n",
       "      <th>model_ref</th>\n",
       "      <th>Brier score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>iris</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.071075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>iris</td>\n",
       "      <td>1</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.076325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>iris</td>\n",
       "      <td>2</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.013939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>digits</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.076327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>digits</td>\n",
       "      <td>1</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.131119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>digits</td>\n",
       "      <td>2</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.318727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>wine</td>\n",
       "      <td>0</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.105201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>wine</td>\n",
       "      <td>1</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.094307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>wine</td>\n",
       "      <td>2</td>\n",
       "      <td>nb</td>\n",
       "      <td>0.054340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_idx data_ref model_idx model_ref  Brier score\n",
       "0        0     iris         0        lr     0.071075\n",
       "1        0     iris         1        rf     0.076325\n",
       "2        0     iris         2        nb     0.013939\n",
       "3        1   digits         0        lr     0.076327\n",
       "4        1   digits         1        rf     0.131119\n",
       "5        1   digits         2        nb     0.318727\n",
       "6        2     wine         0        lr     0.105201\n",
       "7        2     wine         1        rf     0.094307\n",
       "8        2     wine         2        nb     0.054340"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab85c5b",
   "metadata": {},
   "source": [
    "## Save the results (to be used later for IRT training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "invisible-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('./res_base.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
